{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff6e7a1bf60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(3, 5))\n",
    "target = Variable(torch.LongTensor(3).random_(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0590  0.3317  1.2978 -1.3694  0.2554\n",
       " 0.9160  2.4308 -1.3641 -0.4327  0.0316\n",
       "-0.7676 -0.6493  0.0933 -0.9304 -1.1471\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3\n",
       " 0\n",
       " 2\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2.0616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = loss(input, target)\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the code above, we find that the CrossEntropy Loss allows the `input` parameter to be a matrix, which represents a mini-batch output of neural network, each row of the matrix corresponds to one input data. The `target` parameter is a vector, each element is the groundtruth label of the input data. \n",
    "\n",
    "Based on each row of the `input` matrix, the algorithm will first compute the probability of each class of the input data, then will apply the multi-class crossentropy equation.\n",
    "\n",
    "$$\n",
    "crossentropy = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^K y_{true}^{(k)}\\mathrm{log}(y_{predict}^{(k)})\n",
    "$$\n",
    "\n",
    "$y_{true}$ is a K element one-hot vector, if the ground truth is the kth class, then $y_{true}^{(k)}$ will be one and others will be 0.\n",
    "\n",
    "Now, let's calculate the crossentropy seperately to give us more confidence about the above explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.9771 -1.7044 -0.7383 -3.4055 -1.7807\n",
       "-1.8442 -0.3295 -4.1243 -3.1929 -2.7286\n",
       "-1.7959 -1.6776 -0.9350 -1.9587 -2.1754\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = F.softmax(input)\n",
    "log_prob = torch.log(prob)\n",
    "log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 3 examples, the target is `[3,0,2]`, we directely add them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy = -1/3.0*(log_prob[0,3]+log_prob[1,0]+log_prob[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.0616\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is consistent with the previous `ouput`.\n",
    "\n",
    "There is another way to calculate the crossentropy, which is said to be more precise and stable than using softmax activation funtion in the network to get a probablility output. The method uses `torch.nn.LogSoftmax` as activation function, and use `torch.nn.NLLLoss` as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.9771 -1.7044 -0.7383 -3.4055 -1.7807\n",
       "-1.8442 -0.3295 -4.1243 -3.1929 -2.7286\n",
       "-1.7959 -1.6776 -0.9350 -1.9587 -2.1754\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob = F.log_softmax(input)\n",
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy = F.nll_loss(log_prob, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.0616\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also correct. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
